<rss version="2.0">
<channel>
<title>Brandon Rohrer</title>
<link>https://www.brandonrohrer.com</link>
<description>Brandon Rohrer's blog</description>



  <item>
    <title>
    Artisanal Language Models
    </title>
    <link>
    https://brandonrohrer.com/alms.html
    </link>
    <pubDate>
    Wed, 18 Feb 2026 08:36:00 EDT
    </pubDate>
    <guid>
    https://brandonrohrer.com/alms.html
    </guid>
    <description><![CDATA[


<p>
Large Language Models are everywhere, and in February 2026
it's hard to imagine what the machine learning world would look like
without them. But it's fun to imagine some alternatives.
</p>

<h2><a id="What-if-an-LLM-were-trained-to-complete-a-specific-task?"></a><a href="#What-if-an-LLM-were-trained-to-complete-a-specific-task?">What if an LLM were trained to complete a specific task?</a></h2>

<p>
LLMs are general purpose tools, trained to be able to do many
different things. As a result they are vast. And they are better at
doing some things than others.
</p>

<p>
If an LLM were instead focused on a particular task, trained to perform it
as well as possible and ignore everything else, then it would have
a better chance at being excellent at that thing, rather than just
being OK at everything.
</p>

<p>
The structure around the model, the preprocessing of the input data and
postprocessing out the output data, could all be specially built to
give the best results on a single task. Whether for document retrieval
or spell checking or autocomplete or interactive chat, whether for text or
for photos or for music, an Artisanal Language Model could be focused
on doing one thing and doing it well.
</p>

<h2><a id="What-if-we-could-train-an-LLM-on-a-data-set-we-collected-ourselves?"></a><a href="#What-if-we-could-train-an-LLM-on-a-data-set-we-collected-ourselves?">What if we could train an LLM on a data set we collected ourselves?</a></h2>

<p>
LLMs are trained on practically the whole internet.
</p>

<p>
The downside on such a broad swath of training data is that LLMs are also
trained on every stupid thing someone decided to post in a drunken rant.
ML engineers try to correct for this with post-processing filter steps
and prescriptive prompts, but there's no way to completely eliminate
idiocy from the model once it's been trained in.
</p>

<p>
With a set of curated training
data, every inclusion is a deliberate decision, and garbage-in-garbage-out
becomes less of a problem.
Curated training data would also avoid the many legal and ethical viiolations
called out in the training sets of popular LLMs, including copyright
violation, license violation, nonconsensual sharing of personal images,
and inclusion of CSAM.
</p>

<p>
Another advantage of an ALM focused on a specific task is that it can
limit its training data to what is relevant to the problem at hand.
If building a Javascript code completion model, we wouldn't need to include
large amounts of prose every language of the world, or even code in other
computer languages. We wouldn't need to include catalogs of audio recordings
or millions of images. We could limit the training data to Javascript, making
it orders of magnitude smaller.
</p>

<p>
With smaller training data sets, training itself becomes more feasible.
For LLMs we can count on one hand the companies large enough to train their
own general purpose models from scratch. The investment in data engineering
and computation is huge. But for a training data set that is 0.01% of
the size, the training time and cost come down within the reach of
many more organizations, researchers, and hobbyists.
</p>

<h2><a id="What-if-an-LLM-could-be-trained-on-CPUs?"></a><a href="#What-if-an-LLM-could-be-trained-on-CPUs?">What if an LLM could be trained on CPUs?</a></h2>

<p>
Training a modern LLM requires centuries of GPU time. This gets spread across
many thousands of GPUs so that it completes in a reasonable amount of time,
but it remains massive. And it results in huge hardware and power bills.
</p>

<p>
If a much smaller model were capable of being trained on CPU only, even if
it required many of them, it would remove a huge barrier to language model
training. The rate of experimentation, innovation, diversification, and
specialization would increase tremendously.
</p>

<h2><a id="What-if-an-LLM-could-run-on-your-laptop?"></a><a href="#What-if-an-LLM-could-run-on-your-laptop?">What if an LLM could run on your laptop?</a></h2>

<p>
The current generation of LLMs require clusters of GPUs for inference.
Even after they are
trained, they require too much computation and hardware to sit comfortably
in anything but a data center.
</p>

<p>
If there were language models small enough to run on a laptop and nimble
enough to return inference results quickly on laptop hardware, their
deployment could be made more robust. No network latency, no reliance on
connectivity, no dependence on external services' uptime. The reliability
engineering would become considerably more straightforward and the
expectations of availability could be raised.
</p>

<p>
This also opens the way for proprietary models and applications requiring
high security. The ability to run isolated from an external network
opens up new domains.
</p>

<h2><a id="What-if-an-LLM-could-continue-to-learn-as-you-use-it?"></a><a href="#What-if-an-LLM-could-continue-to-learn-as-you-use-it?">What if an LLM could continue to learn as you use it?</a></h2>

<p>
Current LLMs are too unwieldy to be updated on the fly. While there are
ways to refine them, such as fine tuning or reinforcement learning
from human feedback, these are either tweaks to a small part of the model
or post-processing steps. They aren't capable of updating the model as a whole.
</p>

<p>
If it were possible to update the model based on every interaction, every
new bit of input data and user response, that would make it possible for
the model to get better over time in a meaningful way. And most importantly,
it would continue to adapt to the specific users, tasks, and input data
it was exposed to. It would learn the parameters of its job under
the continuous mentorship of its human users.
</p>

<p>
<br>
<br>
What if we had Artisanal Language Models?
</p>

<p>
I hope to find out.
</p>

    ]]></description>
  </item>

  <item>
    <title>
    Graffiti Wall: A commons drawing app
    </title>
    <link>
    https://graffitiwall.nexus/graffiti_wall.html
    </link>
    <pubDate>
    Mon, 09 Feb 2026 08:36:00 EDT
    </pubDate>
    <guid>
    https://graffitiwall.nexus/graffiti_wall.html
    </guid>
    <description><![CDATA[
<p>
I made public space where anyone and everyone can go and scribble anonymously.
Probably a mistake, but it taught me a lot.
</p>
<p>
<a href="https://graffitiwall.nexus/graffiti_wall.html">
Graffiti Wall</a> (
<a href="https://codeberg.org/brohrer/graffitiwall.nexus">
  frontend code</a>,
<a href="https://codeberg.org/brohrer/graffitiwall-server">
  backend code</a>)
</p>
<p>
It's the latest step on my journey, stitching together everything
I've been learning about
self-hosting, deploying a WSGI server, and backing it with a
Postgres database.
</p>
<p>
Please enjoy it!
</p>

    ]]></description>
  </item>


  <item>
    <title>
    An addition app
    </title>
    <link>
    https://graffitiwall.nexus//graffiti_adder.html
    </link>
    <pubDate>
    Sun, 28 Dec 2025 08:36:00 EDT
    </pubDate>
    <guid>
    https://graffitiwall.nexus//graffiti_adder.html
    </guid>
    <description><![CDATA[
<p>
I made a little
<a href="https://graffitiwall.nexus/graffiti_adder.html">
Addition App</a> (
<a href="https://codeberg.org/brohrer/graffitiwall.nexus">
  frontend code</a>,
<a href="https://codeberg.org/brohrer/graffitiwall-server">
  backend code</a>)
to stitch together everything I've been learning about
self-hosting, deploying a WSGI server, and backing it with a
Postgres database.
</p>
<p>
Please enjoy it!
</p>

    ]]></description>
  </item>


  </channel>
</rss>
