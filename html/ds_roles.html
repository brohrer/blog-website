<!DOCTYPE html>
<html>

  <script type="text/javascript">var blog_title = "What does a Data Scientist do in 2026?";</script>
  <script type="text/javascript">var publication_date = "February 14, 2026";</script>
  <head>
    <link rel="icon" href="images/ml_logo.png">
    <meta charset='utf-8'>
    <meta name=viewport content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/print.css" media="print">
    <base target="_blank">
    <script src="javascripts/blog_head.js"></script>
  </head>
  <body>
    <script src="javascripts/blog_header.js"></script>
    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">


<p>
I became a data scientist in 2013 when the title was young.
It was so new that most companies had no idea what a data scientist should
be doing, only that they desperately needed one or they would be left behind.
Sound familiar?
</p>

<p>
I've tried to survey the job description of data science a couple of times with
varying degrees of success, most recently
to go with 
<a href="https://github.com/brohrer/academic_advisory">some informal recommendations</a>
for creating data science degree programs.
Together with a group of colleages we tried to summarize
<a href="https://github.com/brohrer/academic_advisory/blob/main/what_DS_do.md">what data scientists do</a>
and <a href="https://brandonrohrer.com/data_science_archetypes.html">the data science subtypes of maker, oracle, detective, generalist</a>.
But in the face of changing expectations this doesn't feel like enough
anymore. It's time for a refresh.
</p>

<h2><a id="A-brief-and-biased-history-of-the-Data-Scientist-role"></a><a href="#A-brief-and-biased-history-of-the-Data-Scientist-role">A brief and biased history of the Data Scientist role</a></h2>

<h3><a id="In-the-beginning..."></a><a href="#In-the-beginning...">In the beginning...</a></h3>

<p>
When data science first got huge organizations expected
data scientists to spin straw into gold&mdash;to transform
unorganized data archives into profit. Big Data, it was believed,
held inherent value, which only needed to be coaxed into cash form.
This rarely panned out, so the
approach evolved into a) data scientists produce "insights" and then
b) "insights" generate profit. This also proved elusive in the end.
Eventually data scientists settled into various niches involving
<em>answering questions using data</em>, and some companies decided they didn't
need as many data scientists as they had originally thought.
</p>

<h3><a id="The-Neural-Network-era"></a><a href="#The-Neural-Network-era">The Neural Network era</a></h3>

<p>
Then came the Neural Network revolution, where the machine learning
hammer of choice became the convolutional neural network and many
problems got recast as an image recognition problem. The software
engineering, data engineering, and operations engineering that production
CNNs required merited the job title of Machine Learning Engineer.
Image recognition became synonymous with "modern machine learning".
A data scientist's job description got blurry. Did it include ML
Engineering as a subset? Should a good data scientist candidate have
CNN experience? Every team took their own stance. No consensus emerged.
</p>

<h3><a id="The-age-of-Large-Language-Models"></a><a href="#The-age-of-Large-Language-Models">The age of Large Language Models</a></h3>

<p>
Then the spotlight abruptly shifted to Transformers and Large Language Models.
With their massive scale, the engineering and operations requirements
increased yet again. Only a small handful of enterprises are even
capable of training such a model, and they accomplish this only with
an army of engineers and an unfathomable amount of specialized computing
power. LLMs are effectively black boxes. Their structure is known but their
vast collection of parameters makes their behavior unpredictable and
inexplicable. Using them is a matter of API calls, rather than
training and evaluation. Most importantly, they are generative, rather than inductive. They
don't actually answer questions, they create answer-looking things that
are correct often enough to lull us into complacency.
</p>

<p>
LLMs are far enough removed from a core data scientist's skillset that
their care and feeding isn't part of the data science job description.
But they can still have a big effect on a data scientist's day.
(More on that below.)
</p>

<h3><a id="The-next-Big-Thing"></a><a href="#The-next-Big-Thing">The next Big Thing</a></h3>

<p>
The next hot new trend has not yet emerged, but if the historical 5 year cycle
holds true, it's due any day now.
</p>

<h3><a id="The-Before-Times"></a><a href="#The-Before-Times">The Before Times</a></h3>

<p>
On the pre-history side, the field of data science was named in 1997,
and the discipline has existed by other names
for a very long time. After all,
people have been answering questions using data for thousands of years.
</p>

<h2><a id="Answering-questions-with-data"></a><a href="#Answering-questions-with-data">Answering questions with data</a></h2>

<h3><a id="Decision-support:-Which-choice-should-I-make?"></a><a href="#Decision-support:-Which-choice-should-I-make?">Decision support: Which choice should I make?</a></h3>

<h3><a id="Experimentation:-Which-version-is-better?"></a><a href="#Experimentation:-Which-version-is-better?">Experimentation: Which version is better?</a></h3>

<h3><a id="Personalization:-Which-one-should-I-show-you?"></a><a href="#Personalization:-Which-one-should-I-show-you?">Personalization: Which one should I show you?</a></h3>

<h3><a id="Optimization:-Which-plan-is-the-best?"></a><a href="#Optimization:-Which-plan-is-the-best?">Optimization: Which plan is the best?</a></h3>

<p>
Price optimization - how much should I charge this customer for this thing or
service?
</p>

<p>
Tip/donation recommendation - what suggestions should I give someone for how
much to give?
</p>

<h3><a id="Product-experience:-Which-pages-to-users-visit?-What-buttons-to-they-click?
What-features-do-they-use?-What-does-this-tell-us-about-how-we-can-improve
their-experience?"></a><a href="#Product-experience:-Which-pages-to-users-visit?-What-buttons-to-they-click?
What-features-do-they-use?-What-does-this-tell-us-about-how-we-can-improve
their-experience?">Product experience: Which pages to users visit? What buttons to they click?
What features do they use? What does this tell us about how we can improve
their experience?</a></h3>

<h2><a id="The-perrenial-promise-of-self-serve"></a><a href="#The-perrenial-promise-of-self-serve">The perrenial promise of self-serve</a></h2>

<p>
Every DS organization I've worked in has gone through this cycle:
</p>

<ol>
<li> Data scientists generate useful results</li>
<li> Stakeholders find them valuable</li>
<li> Stakeholders ask for more such results, with increasing frequency</li>
<li> DSs get tired of running similar queries over and over</li>
<li> A "self-serve analytics" function is proposed</li>
</ol>

<p>
I've never seen this approach solve the original problem of getting stakeholders
all the information they need without burdening the DSs. Either
</p>

<ul>
<li> a basic self-serve system is fielded, which inevitably leads to follow-up
questions outside of its scope</li>
<li> a complex self-serve system is fielded, which requires stakeholders to
learn a querying language, like SQL or a simplified version of it.
They don't, and DSs remain in the role of human user interface.</li>
<li> DSs get deep into building an intuitive, highly capable
self-serve system. The project stope is large and they and aren't available
to field query questions of any sort.</li>
</ul>

<h2><a id="When-stakeholders-prefer-a-cheap,-fast-wrong-answer-to-a-good-one"></a><a href="#When-stakeholders-prefer-a-cheap,-fast-wrong-answer-to-a-good-one">When stakeholders prefer a cheap, fast wrong answer to a good one</a></h2>

<p>
The biggest impact of AI (large language model) assistants on data science
is the idea that anyone can query data with natural language Q-and-A.
Sadly the reality of such systems is that they are trained on data
that doesn't share the same set of quirks and idiosyncracies that your
org is working with. It produces condifent, plausible answers 100% of the
time, but they are accurate only 70% of the time, and the problem is that
you can't know whether a particular answer is in the 30% until you
dive in and re-create the analysis yourself.
</p>

<p>
There is a school of thought that being confident and fast is better than
being cautious and correct. 
It has bled over from strategic leadership (where
ambiguity is ubiquitous and one of the greatest risks is indecision)
to analysis and engineering (where incaution can lead to loss of limb,
life, or money). And in most large organizations, individual stakeholders
don't often get to feel the effects of being wrong. Those usually take time to
materialize. So they can prioritize being fast and confident, which
their AI analytics queries are all to happy to help them out with.
</p>

<h2><a id="When-stakeholders-undervalue-to-skill-and-underestimate-the-time-required"></a><a href="#When-stakeholders-undervalue-to-skill-and-underestimate-the-time-required">When stakeholders undervalue to skill and underestimate the time required</a></h2>

<p>
A closely related trend is a common assumption that data analysis has
somehow gotten easier and faster. 
Randy Au calls this <a href="https://www.counting-stuff.com/data-work-in-the-fast-fashion-code-era/">"data work in the fast fashion code era"</a>.
It's no big deal to extract nuanced insights from your collected data,
just feed it in to NotebookLM and ask, right? You should be able to have
something by this afternoon right? Not the full analysis of course, but
"rough numbers". Right?
</p>

<p>
I can't even come up with a rough number of the times I've had the conversation
that "rough numbers" are very rough indeed. Not just off by a few percent,
but maybe in the completely wrong direction. And there's no way to know for
sure until you go back and do the careful numbers.
</p>

        <script src="javascripts/blog_signature.js"></script>
      </section>
    </div>
    <script src="javascripts/blog_footer.js"></script>
  </body>
</html>
